Redis

[TOC]

![img](https://static001.geekbang.org/resource/image/79/e7/79da7093ed998a99d9abe91e610b74e7.jpg?wh=2001*1126)

![img](https://static001.geekbang.org/resource/image/70/b4/70a5bc1ddc9e3579a2fcb8a5d44118b4.jpeg?wh=2048*1536)

## 一、对象和数据结构

### 键和值用什么结构组织？

Redis 使用了一个哈希表来保存所有键值对。我们只需要一次计算就能找到相应的键。

### 为什么哈希表操作变慢了？

哈希冲突，使用链地址法解决。

哈希冲突指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。同一个哈希桶中的多个元素用一个链表来保存，它们之间用指针连接。

#### rehash

解决哈希冲突链过长

rehash 也就是增加现有的哈希桶数量，减少单个桶中的元素数量，从而减少单个桶中的冲突。

##### 过程

使用了两个哈希表。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：

1. **分配空间**：给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
2. **重新散列**：把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中（渐进式rehash）；
3. **释放原空间**：释放哈希表 1 的空间。

到此，我们就可以从哈希表 1 切换到哈希表 2，而原来的哈希表 1 留作下一次 rehash 扩容备用。

##### 渐进式 rehash

第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，影响 Redis 性能，所以 Redis 采用了渐进式 rehash。

简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求，即每次对字典执行添加、删除、查找或者更新操作时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。

这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。

**步骤**：
1、为ht1分配空间，让字典同时持有ht0和ht1两个哈希表
2、在字典中维持一个索引计数器变量rehashidx，设为0，表示rehash开始
3、在rehash期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了除了执行指定的操作以外，还会顺带将ht0哈希表在rehashidx索引上的所有键值对rehash到ht1，当rehash工作完成之后，程序将rehashidx属性的值增1
4、随着字典操作的不断执行，最终在某个时间点上，ht0的所有键值对rehash到ht1，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成
好处：采取**分而治之**的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。

##### 什么时候rehash

扩展：1、服务器没有执行bgsave命令或者bgrewriteAOF命令，并且负载因子>=1；2、服务器正在执行bgsave命令或者bgrewriteAOF命令，并且负载因子>=5（已保存节点数量/哈希表大小）
原因：执行命令的过程中需要创建当前服务器进程的子进程，而大多数操作系统都采用**写时复制**技术来优化子进程的使用效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而**尽可能的避免在子进程期间进行哈希表扩展操作，这可以避免不必要的内存写入操作，最大限度地节约内存。**
收缩：负载因子小于0.1

##### redis和hashmap区别

（1）Redis中有缩容，Java中没有

（2）Redis中的扩容不是一次完成的，可以分多次，是渐进式地，而Java的是一次完成的

### 集合数据操作效率

#### 五种对象

- **字符串对象：** 

  - 如果保存的是整数值，那么使用**整数类型**来保存。
  - 如果保存的是字符串，并且长度大于39字节，则使用**简单动态字符串**（sds）来保存这个字符串值

- **列表对象：**

  - **压缩列表**：当所有字符串元素的长度都小于64字节，列表元素保存的元素数量小于512个。
  - **双向链表**

- **hash对象：**

  - **压缩列表**：（所有键值对的键和值的字符串长度小于64字节；
    保存的键值对数量小于512个。先加键，再加值，键值对的两个节点在一起。）

  - **哈希表**（键和值都是字符串对象）

- **集合对象：**

  - **整数数组**：（所有元素都是整数值，数量不超过512个）；
  - **哈希表**：（键保存元素，值设为null），

- **有序集合对象：**

  - **压缩列表**（元素数量小于128，长度小于64字节。每个元素用两个压缩列表节点保存，第一个保存成员，第二个保存分值。元素按照分值从小到大进行排序。
  - **zset结构 = 跳表 + 字典**（zset中的跳跃表按分值从小到大保存所有集合元素，跳跃表节点的object属性保存了元素的成员，跳跃表节点的score属性保存分值，通过跳跃表可以执行范围操作zrank、zrange。zset结构中的dict字典为有序集合创造了一个由成员到分值的映射，字典的键保存成员，值保存分值。可以用O1的复杂度查找给定成员的分值，如zscore命令。

  zset 同时使用跳表和字典来实现，如果只用字典，无法保证有序，排序需要NlogN和额外的N内存空间。如果只用跳表，根据成员查找分值为logN。**为了让有序集合的查找和范围型操作都快。**

  **这两种数据结构会通过指针共享相同元素的成员和分值，所以不会浪费额外内存。**

#### 对象的底层数据结构

##### 简单动态字符串SDS

- 结构：len（数组中已使用字节的数量）、free（未使用字节的数量）、buf[]字节数组
- 特点：
  1. **O(1)获取字符串长度**。
  2. **不会造成缓冲区溢出，因为动态**，先检查，不满足就自动扩展；
  3. **减少修改字符串时带来的内存重分配次数**：
     - **空间预分配**：不仅分配所必须要的空间，还分配额外的未使用空间。
     - **惰性空间释放：**不直接释放，作为未使用空间保留，留着下次扩充用。，
  4. **二进制安全**：使用二进制保存数据，程序不会对其中的任何数据做任何限制、过滤或者假设，数据在写入时是什么样子，被读取时就是什么样子。
  5. **兼容部分C字符串函数**。如strcasecmp对比字符串、strcat追加字符串

##### 整数集合

##### 双向链表

- 双端
- 无环
- 带表头指针和表尾指针：通过list结构的head和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O1
- 带链表长度计数器：len属性计数，获取链表节点数量的复杂度为O1

整数数组和双向链表很常见，它们的操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度基本是 O(N)，操作效率比较低；

##### 哈希表

##### 压缩列表

为了节约内存而开发的顺序性数据结构，表头字段 zl bytes、zl tail 和 zl len，分别表示**列表长度**、**列表尾的偏移量**和**列表中的 entry 个数**；表尾字段 zl end，表示列表结束。

在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。

- 添加新节点或者删除节点，可能会引发连锁更新操作（连续多次扩展空间）

压缩节点的各个组成部分：

> previous_entry_length | encoding | content

**previous_entry_length**

 记录**前一个节点的长度。**这个属性的长度可以是1字节或5字节，如果前一个小于254则使用1字节，反之使用5字节。

- 可以根据当前节点的起始地址来计算出前一个节点的起始地址，进而回溯到表头。

**encoding**

记录数据信息：类型和长度。

**content**

保存值。

**连锁更新**

添加或删除节点都有可能引发「连锁更新」。

假设现在有一些长度为252字节的节点，他们在`previous_entry_length`中保存为1字节。现在插入了一个260字节的新节点，`new` 将成为 `e1` 的前置节点。

![img](https://bucket-1259555870.cos.ap-chengdu.myqcloud.com/20200102162612.png)

因为 `e1` 的 `previous_entry_length` 属性仅长 `1` 字节， 它没办法保存新节点 `new` 的长度， 所以程序将对压缩列表执行空间重分配操作， **并将`e1` 节点的 `previous_entry_length` 属性从原来的 `1` 字节长扩展为 `5` 字节长。**

由于`previous_entry_length` 的变化，导致`e1`的长度也发生了变化252+4=256>254252+4=256>254，所以导致`e2`也必须更新它的`previous_entry_length` 。这就是连锁更新。

在最坏的情况下，需要执行*N*次重分配操作，而每次空间重分配的最坏复杂度是*O(N)*，合起来就是*O(N^2)*。

尽管如此，连锁更新造成性能问题的概率还是比较低的：

1. 压缩列表里有多个连续的、长度介于250和253字节之间的节点，连锁更新才有可能触发。
2. 即使出现连锁更新，只要需要更新的节点数量不多，性能也不会受影响。

##### 跳表

有序链表只能按顺序On查找元素，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。

一级索引：从第一个元素开始，每两个元素选一个出来作为索引。这些索引再通过指针指向原始的链表。

二级索引：从一级索引中，再抽取部分元素作为二级索引。

整个**查找过程就是在多级索引上跳来跳去，最后定位到元素**。跳表的平均查找复杂度有 O(logN)。

#### 为什么使用整数数组和压缩列表

整数数组和压缩列表在查找时间复杂度方面并没有很大的优势。

两方面原因：

1、内存利用率。都是非常紧凑的数据结构，比链表占用的内存要更少。**Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。**

2、**数组对CPU高速缓存支持更友好**。所以Redis在设计时，集合数据元素较少情况下，默认采用整数数组和压缩列表这种内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。

**cpu缓存是以缓存行组成的，每个缓存行通常是64字节。**Redis底层的使用数组和压缩链表对数据大小限制在64个字节以下，当大于64个字节会改变存储数据的数据结构，所以随机访问对于CPU高速缓存没啥影响。

## 二、高性能IO模型：为什么单线程Redis能那么快？

Redis 是单线程，主要是指 Redis 的**网络 IO 和键值对读写**是由一个线程来完成的。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

### Redis 为什么用单线程？

#### 多线程的开销

多线程编程会面临**共享资源的并发访问控制**问题。**线程切换和相互等待**带来开销。这也会降低系统代码的**易调试性**和**可维护性**。

#### 单线程 Redis 为什么那么快？

- Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表。

- Redis 采用了多路复用机制，使其在网络 IO 中能**并发处理**大量的**客户端请求**，实现高吞吐率。

##### 基本 IO 模型与阻塞点

以 Get 请求为例，为了处理一个 Get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析请求（parse），读取键值数据（get），向 socket 中写回数据返回结果（send）。

###### 阻塞模式下

阻塞点，分别是 **建立连接** 和 **读取请求**。

当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。

类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。

###### 非阻塞模式

在 socket 模型中，不同操作调用后会返回不同的套接字类型。调用 listen() 方法，返回监听套接字，此时可以监听客户端。最后，调用 accept() 方法与客户端建立连接，并返回已连接套接字。

**针对监听套接字设置非阻塞模式**：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。

虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。

**针对已连接套接字设置非阻塞模式**：Redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis。

这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据。

###### 基于多路复用的高性能 I/O 模型

Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，**允许内核中同时存在多个监听套接字和已连接套接字。**内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。

为了在请求到达时能通知到 Redis 线程，select/epoll 提供了**基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。**

select/epoll 一旦监测到有请求到达时，就会触发相应的事件。这些事件会被放进一个**事件队列**，Redis 单线程对该事件队列不断进行处理。

这样Redis 无需一直轮询，避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。

## 三、AOF日志：宕机了，Redis如何避免数据丢失？

### AOF 日志是如何实现的？

AOF 日志是写后日志，意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。记录的是 Redis 收到的每一条**命令**，以**文本**形式保存。相当于mysql **binlog**中的statement格式。

 redo log（重做日志），记录的是修改后的数据。

**好处**：

- 系统执行命令，只有命令能执行成功，才会被记录到日志中。可以**避免出现记录错误命令的情**况。

- 是在命令执行后才记录日志，**不会阻塞当前的写操作。**

**风险**

- 如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就**有丢失的风险**。

- **AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。**这是因为，**AOF 日志也是在主线程中执行的**，把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。

这两个风险都是和 AOF 写回磁盘的时机相关的。我们可以控制 AOF 日志写回磁盘的时机解除风险。

#### 三种写回策略

AOF 配置项 appendfsync 的三个可选值。

- **Always**，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
- **Everysec**，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的*内存缓冲区*，每隔一秒把缓冲区中的内容写入磁盘；
- **No**，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

“同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个落盘操作，**不可避免地会影响主线程性能**；

“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的**数据就丢失**了；

“每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。

#### 日志文件太大了怎么办？

AOF 文件过大带来的性能问题：

一是，文件系统本身对文件大小有限制，无法保存过大的文件；

二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；

三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。

##### AOF 重写机制

对**过大的**AOF文件进行重写，来压缩AOF文件。

实现：检查当前键值数据库中的键值对，记录键值对的最终状态，从而实现对 某个键值对 重复操作后产生的多条操作记录压缩成一条 的效果。进而实现压缩AOF文件的大小。AOF的重写不是根据原有的AOF去做，而是**根据当前内存数据库的数据，去生成一条条命令进行保存。**

##### AOF 重写会阻塞吗?

和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，避免了阻塞主线程。

fork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据。bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。

因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，**第一处日志就是指正在使用的 AOF 日志**，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。

**第二处日志，就是指新的 AOF 重写日志**。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。

总结来说，每次 AOF 重写时，Redis 会**先执行一个内存拷贝**，用于重写；然后，使用**两个日志**保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。

###### AOF 日志重写过程潜在的阻塞风险

fork子进程 和 AOF重写过程中父进程产生写入的场景。

- fork子进程，fork这个瞬间一定是会阻塞主线程的，fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是**拷贝内存页表**（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。

- fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。

###### AOF 重写也有一个重写日志，为什么共享使用 AOF 日志

AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。

## 四、内存快照：宕机后，Redis如何实现快速恢复？

使用 AOF 进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上 Redis 的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了。那么，有没有既能避免数据丢失，又能更快地恢复的方法呢？当然有，那就是 **RDB 快照**了。

内存快照。就是指内存中的数据在**某一个时刻的状态记录**。和 AOF 相比，**RDB 记录的是某一时刻的数据，并不是操作**。

在数据恢复时，可以直接把 RDB 文件读入内存，快速完成恢复。但还要考虑两个关键问题：

对哪些数据做快照？这关系到快照的**执行效率**问题；

做快照时，数据还能被增删改吗？这关系到 **Redis 是否被阻塞**，能否同时正常处理请求。

### 给哪些内存数据做快照？

Redis 执行的是**全量快照**，把内存中的所有数据都记录到磁盘中。

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。

- save：在主线程中执行，会导致阻塞；

- bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。

### 快照时数据能修改吗?

使用 bgsave 时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。

为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提供的**写时复制技术（Copy-On-Write, COW）**，在执行快照的同时，正常处理写操作。

bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。此时，如果主线程对这些数据也都是读操作，那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据写入 RDB 文件。

这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。

### 可以每秒做一次快照吗？

虽然 bgsave 执行时不阻塞主线程，但是，**如果频繁地执行全量快照，也会带来两方面的开销。**

一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。

另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程）。那么，有什么其他好方法吗？

此时，我们可以做**增量快照**，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。

但是，这么做的前提是，我们需要记住哪些数据被修改了。这会带来额外的空间开销问题。

Redis 4.0 中提出了一个**混合使用 AOF 日志和内存快照**的方法。简单来说，**内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。**

这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。

第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。

##### 建议：

数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；

如果允许分钟级别的数据丢失，可以只使用 RDB；

如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。

## 五、数据同步：主从库如何实现数据一致？

Redis 具有高可靠性：一是**数据尽量少丢失**，二是**服务尽量少中断**。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加**副本**，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，其他实例也可以对外提供服务，不会影响业务使用。

Redis 的主从库模式采取读写分离的方式。

- **读操作**：主库、从库都可以接收；

- **写操作**：先到主库执行，再同步给从库。

### 为什么要读写分离？

如果都能接收写操作：客户端对同一个数据修改了三次，每一次的修改请求都落在不同的实例上，那么这个数据在三个实例上的副本就不一致。就可能读取到旧的值。

如果我们非要保持这个数据在三个实例上一致，就要涉及到**加锁、实例间协商是否完成修改**等一系列操作，会带来巨额的开销。

采用了读写分离后，所有数据的修改只会在主库上进行，不用协调三个实例。主库有了最新的数据后，会同步给从库，这样保证了主从库的数据一致。

### 主从库间第一次同步

![img](https://static001.geekbang.org/resource/image/63/a1/63d18fd41efc9635e7e9105ce1c33da1.jpg)

1. 主从库间建立连接、协商同步。**从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。**

   从库给主库发送 psync 命令，表示要进行数据同步，psync 命令包含了**主库的 runID** 和**复制进度 offset** 两个参数。

   - runID，是每个 Redis 实例的唯一标记。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。
   - offset，设为 -1，表示第一次复制。

2. 主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。

   **FULLRESYNC 响应表示第一次复制采用的全量复制，主库会把当前所有的数据都复制给从库。**

   主库执行 bgsave 命令，生成 RDB 文件发给从库。从库接收到 RDB 文件后，先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。

   在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的缓冲区 replication buffer，记录 RDB 文件生成后收到的所有写操作。

3. 主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。

### 主从级联模式分担全量复制时的主库压力

全量复制中两个耗时的操作：生成 RDB 文件和传输 RDB 文件。

如果从库数量很多，导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。**fork 这个操作会阻塞主线程处理正常请求。传输 RDB 文件也会占用网络带宽。**

“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。

我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。让其他的一些从库和刚才所选的从库，建立起主从关系。

```mysql
replicaof  所选从库的IP 6379
```



这样这些从库在进行同步时，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力。

主从库完成了全量复制之后会维护一个长链接，主库会将后续陆续收到的命令操作同步给从库，这个过程称为**基于长连接的命令传播**，可以避免频繁建立连接的开销。

这个过程中存在着风险点，最常见的就是**网络断连或阻塞**。主从库之间无法进行命令传播保持数据一致。

### 主从库间网络断了怎么办？

**注意**

1. 一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。

2. 每个从库会记录自己的**复制进度**slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。

主从库会采用增量复制的方式继续同步。听名字大概就可以猜到它和全量复制的不同：全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。

当从库断连又重连之后，通过psync命令告诉主库自己的slave_repl_offset，然后主库根据自己的master_repl_offset和slave_repl_offset来判断是需要全量同步还是把两者之间的命令增量同步给从库（同步的方式就是通过主库与每个从库建立连接之后的这个所谓的replication buffer）

**replication buffer**：

- Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。
- 既然有这个内存buffer存在，那么这个buffer有没有限制呢？如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM。所以Redis提供了client-output-buffer-limit参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说**从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接**，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。

**repl_backlog_buffer**：

- repl_backlog_buffer 是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己已经读到的位置。**

- 只要有从库存在，这个repl_backlog_buffer就会存在。主库的所有写命令除了传播给从库之外，都会在这个repl_backlog_buffer中记录一份，缓存起来，只有预先缓存了这些命令，当从库断连后，从库重新发送psync $master_runid $offset，**主库才能通过$offset在repl_backlog_buffer中找到从库断开的位置，只发送$offset之后的增量数据给从库即可。**

刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。

同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。

![img](https://static001.geekbang.org/resource/image/13/37/13f26570a1b90549e6171ea24554b737.jpg)

主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。

在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，**主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。**

- 因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。**如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。**

因此，我们要想办法避免这一情况，一般而言，我们可以调整 **repl_backlog_size** 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。

举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2MB 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把 repl_backlog_size 设为 4MB。

这样一来，增量复制时主从库的数据不一致风险就降低了。如果并发请求量非常大，可以考虑使用切片集群来分担单个主库的请求压力。

### 主从全量同步使用RDB而不使用AOF的原因

1、RDB文件内容是经过**压缩的二进制数据**，文件很小。而AOF文件记录的是每一次写操作的**命令**，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以减少带宽消耗，从库在加载RDB文件时，一是文件小，二是直接按照RDB协议解析二进制数据还原数据即可，读取速度快。而AOF需要依次执行每个写命令，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。

2、假设要使用AOF做全量同步，意味着必须打开AOF功能，**打开AOF就要选择文件刷盘的策略**，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。

## 六、哨兵机制：主库挂了，如何不间断服务？

三个问题：

1. 主库真的挂了吗？
2. 该选择哪个从库作为主库？
3. 怎么把新主库的相关信息通知给从库和客户端呢？

### 哨兵机制的基本流程

哨兵是一个 **Redis 进程**，主要负责三个任务：监控、选主（选择主库）和通知。

**监控**：哨兵进程会周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果主库或从库没有按时响应，哨兵就会判定下线，开始**切换主库**。

**选主**：主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。

**通知**：哨兵会把新主库的连接信息发给其他**从库**，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给**客户端**，让它们把请求操作发到新主库上。

在监控和选主中，哨兵需要做出两个决策：

- 在监控中，哨兵需要判断主库是否处于下线状态；
- 在选主中，哨兵也要决定选择哪个从库实例作为主库。

### 主观下线和客观下线

**哨兵会使用 PING 命令检测它自己和主、从库的网络连接情况。**如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。

如果检测的是主库，为了防止哨兵误判（集群网络压力较大、网络拥塞，主库本身压力较大），避免不必要的开销（选主，同步）。

**采用哨兵集群。**引入多个哨兵实例一起来判断，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。

### 如何选定新主库？

先筛选，在打分。

- 筛选：**检查从库的当前在线状态，以及之前的网络连接状态。**如果从库总是和主库断连，而且断连次数超出了一定的阈值，就可以把这个从库筛掉了。配置项 down-after-milliseconds * 10。主从库断连的最大连接时间、发生断连的最大次数次数10 次

- 打分：三个规则分别是**从库优先级、从库复制进度以及从库 ID 号**。只要在某一轮中，有从库得分最高，那么它就是主库了，结束选主。如果没有出现得分最高的从库，那么就继续进行下一轮。

**第一轮：优先级最高的从库得分高。**

用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如可以手动给**内存大**的实例设置一个高优先级。

**第二轮：和旧主库同步程度最接近的从库得分高。**

主从库同步时有个命令传播的过程。在这个过程中，主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。从库的复制进度需要最接近主库的最新写操作。

**第三轮：ID 号小的从库得分高。**

每个实例都会有一个 ID 编号，Redis 在**优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。**

### 小结

- 哨兵集群中有实例挂了
- 由哪个实例来执行主从切换？

**主从库切过程中，客户端能否正常地进行请求操作**

如果客户端使用了读写分离，那么读请求可以在从库上正常执行，写请求会失败。失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。

把写失败的请求**先缓存起来或写入消息队列中间件中**，等哨兵切换完主从后，再把这些写请求发给新的主库。

通过配置（down-after-milliseconds参数）。**配置的时间越短，哨兵越敏感**，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。

哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于**哨兵主动通知客户端。**

如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，**客户端也需要支持主动去获取最新主从的地址进行访问。**

所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。

**1、哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？**

这个属于分布式系统领域的问题了，指的是在分布式系统中，如果存在故障节点，整个集群是否还可以提供服务？而且提供的服务是正确的？

这是一个分布式系统容错问题，这方面最著名的就是分布式领域中的“拜占庭将军”问题了，“拜占庭将军问题”不仅解决了容错问题，还可以解决错误节点的问题

简单说结论：存在故障节点时，只要集群中大多数节点状态正常，集群依旧可以对外提供服务。

**2、哨兵由哪个实例来执行主从切换？**

哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换。

选出“哨兵领导者”是分布式共识算法，指的是集群中多个节点如何就一个问题达成共识。共识算法有很多种，例如Paxos、Raft，这里哨兵集群采用的类似于Raft的共识算法。

简单来说就是每个哨兵设置一个随机超时时间，超时后每个哨兵会请求其他哨兵为自己投票，其他哨兵节点对收到的第一个请求进行投票确认，一轮投票下来后，首先达到多数选票的哨兵节点成为“哨兵领导者”，如果没有达到多数选票的哨兵节点，那么会重新选举，直到能够成功选出“哨兵领导者”。

## 七、哨兵集群

### 基于 pub/sub 机制的哨兵集群组成

哨兵实例之间可以相互发现，归功于 Redis 的发布 / 订阅机制。

哨兵和主库建立起了连接，就可以在主库上发布消息和订阅消息，发布自己的连接信息（IP 和端口）。获得其他哨兵发布的连接信息。**当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。**

为了区分不同应用的消息，Redis 会以频道的形式，对这些消息进行分门别类的管理。**只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。**

在主从集群中，主库上有一个名为“_sentinel__:hello”的频道，哨兵通过它来发布订阅，获取相互的 IP 地址和端口号，建立网络连接，形成哨兵集群。

哨兵还需要和从库建立连接。因为需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步。

**哨兵向主库发送 INFO 命令**，主库会把从库列表返回给哨兵。哨兵和每个从库建立连接并持续监控。

通过 pub/sub 机制，哨兵之间可以组成集群，同时，哨兵又通过 INFO 命令，获得了从库连接信息，也能和从库建立连接，并进行监控了。

哨兵还需要完成把新主库的信息告诉客户端。客户端需要获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。

### 基于 pub/sub 机制的客户端事件通知

每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。

操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。

有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。

### 由哪个哨兵执行主从切换？

“客观下线”的判断过程。

1. 任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应。

2. 获得了仲裁所需的赞成票数（哨兵配置文件中的 quorum 值）后，就可以标记主库为“客观下线”。

3. 这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。

   在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

   哨兵只有一票，想成为 Leader的哨兵先给自己投一张赞成票，然后向 其他哨兵 发送命令，表示要成为 Leader。

   如果一轮投票没有产生 Leader。哨兵集群会等待一段时间（哨兵故障转移超时时间的 2 倍），再重新选举。如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。

如果哨兵集群只有 2 个实例，一个哨兵要想成为 Leader，必须获得 2 票。如果有个哨兵挂了，此时的集群无法进行主从库切换。至少会配置 3 个哨兵实例

### 小结

1. 每轮投票都是只投给自己，无法选出“Leader”

   需要同时判定了主库客观下线。

   - 但不同哨兵的网络连接、系统压力不完全一样，接收到下线协商消息的时间也可能不同。

   - 哨兵对主从库进行的在线状态检查等操作，用一个定时器来完成，一般来说每100ms执行一次这些事件。每个哨兵的定时器执行周期都会加上一个小小的随机时间偏移。

   - 停一段时间（一般是故障转移超时时间failover_timeout的2倍）再进行下一轮投票。

2. 投票投给谁？

   哨兵如果没有给自己投票，就会把票投给第一个给它发送投票请求的哨兵。并拒绝后续请求。

3. 假设有一个 Redis 集群，是“一主四从”，同时配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？此外，哨兵实例是不是越多越好呢，如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处呢？

   1、**哨兵集群可以判定主库“主观下线”**。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。

   2、**哨兵不能完成主从切换。**哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。

4. 哨兵实例是不是越多越好？

   哨兵在判定“主观下线”和选举“Leader”时，都需要和其他节点进行通信，多个哨兵会分布在不同机器上，节点越多通信消耗时长越长、机器故障风险越大，都会导致主从切换时间延长。

5. 调大down-after-milliseconds值，对减少误判是不是有好处？

   **配置的时间越短，哨兵越敏感**，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果**配置的时间比较长**，哨兵越保守，这种情况可以减少哨兵误判的概率，但是**主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多**。

## 八、切片集群：数据增多了，是该加内存还是加实例？

### 如何保存更多数据？

- 纵向扩展：加内存、加磁盘、高配置的 CPU。

- 横向扩展：横向增加当前 Redis 实例的个数。

纵向扩展，**实施起来简单、直接**。当使用 RDB 对数据进行持久化时，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞。会受到硬件和成本的限制。

**在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择。**

- 数据切片后，在多个实例之间如何分布？

- 客户端怎么确定想要访问的数据在哪个实例上？

### 数据切片和实例的对应分布关系

官方的 Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。一个切片集群共有 16384 （2的14次方）个哈希槽，每个键值对都会根据它的 key，映射到一个哈希槽中。

具体的映射过程分为两大步：首先根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

**如果集群中有 N 个实例，每个实例上的槽个数为 16384/N 个。**

也可以根据不同实例的资源配置情况，使用 cluster addslots 命令手动分配哈希槽。但手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。

### 客户端如何定位数据？

Redis 实例会把自己的哈希槽信息发给和它**相连接**的其它实例，当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。

客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。

在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：

- 在集群中，**实例有新增或删除**，Redis 需要重新分配哈希槽；
- 为了**负载均衡**，Redis 需要把哈希槽在所有实例上重新分布一遍。

Redis Cluster 方案提供了一种**重定向机制**：

1. 当客户端给一个实例发送操作时，如果实例上数据，实例就会给客户端返回 MOVED 命令，里面包含了新实例的访问地址，客户端再给一个新实例发送命令。

2. Slot  中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。客户端就会收到一条 ASK 报错信息，告知客户端新实例地址，客户端向新实例发送一个 ASKING 命令。让这个实例允许执行客户端接下来发送的命令。然后客户端再向新实例发送 GET 命令读取数据。

**ASK 命令并不会更新客户端缓存的哈希槽分配信息**。如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，**而 MOVED 命令会更改本地缓存，让后续所有命令都发往新实例。**

**Redis Cluster采用哈希槽的原因：**

如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要**修改表**。如果是单线程操作表，所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外**存储空间**也会增加。

基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是**哈希槽的个数要比键值对的个数少很多**，无论是修改**哈希槽和实例的对应关系**，还是使用**额外空间存储哈希槽和实例的对应关系**，都比直接记录键值对和实例的关系的开销小得多。

##### 主线程、子进程和后台线程的联系与区别

主进程接收客户端发送的请求，并处理读写操作请求。

子进程：

- 创建 RDB ，同时负责在主从同步时传输 RDB 给从库；

- 通过无盘复制方式传输 RDB 的子进程；

- 重写 AOF 日志 bgrewriteaof 子进程。


##### 写时复制的底层实现机制

主线程 fork 出 bgsave 子进程后，bgsave 子进程实际是复制了主线程的页表。页表保存了主线程的所有数据块在内存中的物理地址。bgsave 子进程生成 RDB 时，根据页表读取数据，写入磁盘中。

主线程接收到了新写或修改操作，会使用写时复制机制。写时复制指，主线程在有写操作时，需要新分配一个物理页，会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射。但原页表的映射关系，仍然保留在 bgsave 子进程中。、

**replication buffer 和 repl_backlog_buffer 的区别**

总的来说，replication buffer 是主从库在进行**全量复制**时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了**支持从库增量复制，主库上用于持续保存写操作**的一块专用 buffer。

Redis 主库要把全量复制期间的写操作命令发给从库时，主库**会先创建一个客户端**，用来连接从库，然后通过这个客户端，把写操作命令发给从库。在内存中，主库上的客户端就会对应一个 buffer，这个 buffer 就被称为 replication buffer。**每个从库都有一个对应的客户端。**

repl_backlog_buffer 是一块专用 buffer，**在 Redis 服务器启动后**，开始一直接收写操作命令，这是**所有从库共享**的。**主库和从库会各自记录自己的复制进度**，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。

## 九、代替String的数据结构

###  String 类型内存开销大

我们保存了 1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和图片存储对象 ID 的记录平均用了 64 字节。

一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了。图片 ID 和图片存储对象 ID 都是 10 位数，我们可以用两个 8 字节的 Long 类型表示这两个 ID。因为 8 字节的 Long 类型最大可以表示 2 的 64 次方的数值，所以肯定可以表示 10 位数。但是， String 类型却用了 64 字节。

除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等元数据。

当保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数。

当保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存。

- buf：字节数组，在数组最后加“\0”表示字节数组的结束。
- len：占 4 个字节，表示 buf 的已用长度。
- alloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。

Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。

一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，指针再指向实际数据。

- 当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据。

- 当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。

- 当字符串大于 44 字节时，Redis 会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。

10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。

Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节。

>  Redis 使用内存分配库 jemalloc 
>
> jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。
>

 String 类型保存图片 ID 和图片存储对象 ID 时需要用 64 个字节。

### 用什么数据结构可以节省内存？

压缩列表的构成。表头有三个字段 zlbytes、zltail 和 zllen，分别表示列 表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。

压缩列表用连续的 entry 保存数据。每个 entry 的元数据包括下面几部分。

- prev_len，表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len 取值为 1 字节，否则，就取值为 5 字节。
- len：表示自身长度，4 字节；
- encoding：表示编码方式，1 字节；
- content：保存实际数据。

这些 entry 不需要再用额外的指针进行连接，可以节省指针所占用的空间。

### 如何用集合类型保存单值的键值对？

采用基于 Hash 类型的二级编码方法。把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 value。

hash-max-ziplist-entries：用压缩列表保存时的最大元素个数。

hash-max-ziplist-value：单个元素的最大长度。

Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。

**控制保存在 Hash 集合中的元素个数。**前7位作为键值对的key，Hash集合是键值对的value。

## 十、有一亿个keys要统计，应该用哪种集合？

### 聚合统计

SUNIONSTORE、SDIFFSTORE、SINTERSTORE

统计手机 App 每天的新增用户数和第二天的留存用户数。

key 是 user:id 以及当天日期，例如 user:id:20200803；value 是 Set 集合，记录当天登录的用户 ID。

直接执行这些计算，会导致 Redis 实例阻塞。可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计。

### 排序统计

List 是按照元素进入 List 的顺序进行排序的，当有新元素插入时，List 相同位置上的元素就会发生变化，用 LRANGE 读取时，就会读到旧元素。

 Sorted Set 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。

我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 Sorted Set 中。Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。

假设越新的评论权重越大，目前最新评论的权重是 N，我们执行下面的命令时，就可以获得最新的 10 条评论：

```ZRANGEBYSCORE comments N-9 N```

所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用 Sorted Set。

### 二值状态统计

二值状态统计。指集合元素的取值就只有 0 和 1 两种。在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态.

Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。

String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。你可以把 Bitmap 看作是一个 bit 数组。

Bitmap 提供了 GETBIT/SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的偏移量是从 0 开始算的，也就是说 offset 的最小值是 0。当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位会被设置为 1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个 bit 数组中所有“1”的个数。

在**统计 1 亿个用户连续 10 天的签到**情况时，你可以把每天的日期作为 key，每个 key 对应一个 1 亿位的 Bitmap，每一个 bit 对应一个用户当天的签到情况。

接下来，我们对 10 个 Bitmap 做“与”操作，得到的结果也是一个 Bitmap。在这个 Bitmap 中，只有 10 天都签到的用户对应的 bit 位上的值才会是 1。最后，我们可以用 BITCOUNT 统计下 Bitmap 中的 1 的个数，这就是连续签到 10 天的用户总数了。

现在，我们可以计算一下记录了 10 天签到情况后的内存开销。每天使用 1 个 1 亿位的 Bitmap，大约占 12MB 的内存（10^8/8/1024/1024），10 天的 Bitmap 的内存开销约为 120MB，内存压力不算太大。不过，在实际应用时，最好对 Bitmap 设置过期时间，让 Redis 自动删除不再需要的签到记录，以节省内存开销。

所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个 bit 位就能表示 0 或 1。在记录海量数据时，Bitmap 能够有效地节省内存空间。

### 基数统计

**基数统计就是指统计一个集合中不重复的元素个数。**统计网页的 UV。

网页 UV 的统计需要去重，一个用户一天内的多次访问只能算作一次。

- 用 Set 类型的 SCARD 命令，返回一个集合中的元素个数。

- Hash 类型记录 UV。每个页面都用 Set，就会消耗很大的内存空间。

HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。

在 Redis 中，每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。

可以用 PFADD 命令向 HyperLogLog 中添加新元素，然后用 PFCOUNT 命令返回 HyperLogLog 的统计结果。

## 十一、消息队列

### 消息队列的消息存取需求

假设组件 1 需要对采集到的数据进行计算，并写入数据库，但是，消息到达的速度很快，组件 1 没有办法及时地既做采集，又做计算，并且写入数据库。所以，我们可以使用基于消息队列的通信，让组件 1 把数据保存为 JSON 格式的消息，再发到消息队列，这样它就可以继续接收新的数据了。组件 2 则异步地从消息队列中把数据读取出来，在服务器 2 上进行求和计算后，再写入数据库。

- 消息保序

- 重复消息处理

- 消息可靠性保证

### 基于 List 的消息队列解决方案

- List 本身就是按先进先出的顺序对数据进行存取的。生产者先用 LPUSH 写入，消费者则用 RPOP 把消息依次读出

  **BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。**

- **消费者程序本身能对重复消息进行判断。**一方面，消息队列要能给每一个消息提供全局唯一的 ID 号；另一方面，消费者程序要把已经处理过的消息的 ID 号记录下来。

  当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。这种处理特性也称为幂等性，**幂等性**就是指，对于同一条消息，消费者收到一次的处理结果和收到多次的处理结果是一致的。

  消息的全局唯一 ID 号就需要生产者程序在发送消息前生成。

- 消息可靠性：为了留存消息，List 类型提供了 BR POP LPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。

**消息积压问题**

Streams 持消费组形式的消息读取。

- X ADD：插入消息，保证有序，可以自动生成全局唯一 ID；
- X READ：用于读取消息，可以按 ID 读取数据；
- X READ GROUP：按消费组形式读取消息；
- X PENDING 和 X ACK：X PENDING 命令可以用来查询每个消费组内所有消费者**已读取但尚未确认**的消息，而 XACK 命令用于向消息队列**确认消息处理已完成**。

为了保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息，Streams 会自动使用内部队列（也称为 PENDING List）**留存**消费组里每个消费者**读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成**”。如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。

## 十二、如何应对变慢的Redis？

### Redis 真的变慢了吗？

**查看 Redis 的响应延迟**（redis-cli --latency -h host -p port ），但和软硬件环境相关。

基于**当前环境下的 Redis 基线性能**（redis-cli –intrinsic-latency ）做判断。如果延迟是其基线性能的 2 倍及以上，就可以认定 Redis 变慢了。

用 iPerf 这样的工具，测量从 Redis 客户端到服务器端的网络延迟。

### 如何应对 Redis 变慢？

#### Redis 自身操作特性

##### 1. 慢查询命令

1. **用其他高效命令代替。**比如说，如果你需要返回一个 SET 中的所有成员时，不要使用 SMEMBERS 命令，而是要使用 SSCAN 多次迭代返回，避免一次返回大量数据，造成线程阻塞。
2. **当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 。**
3. **KEYS 命令需要遍历存储的键值对，操作延时高。不建议使用。**

##### 2. 过期 key 操作

过期 key 的自动删除机制，本身会引起 Redis 操作阻塞，导致性能变慢。

Redis 键值对的 key 可以设置过期时间。默认情况下，Redis 每 100 毫秒会删除一些过期 key，具体的算法如下：

1. 采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；
2. 如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。

**删除操作是阻塞的**（Redis 4.0 后可以用异步线程机制来减少阻塞影响）。所以，一旦该条件触发，Redis 的线程就会一直执行删除，这样一来，就没办法正常服务其他的键值操作了，就会进一步引起其他键值操作的延迟增加，Redis 就会变慢。

繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key，会导致在同一秒内有大量的 key 同时过期。

可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。

#### 文件系统：AOF 模式

为了保证数据可靠性，Redis 会采用 AOF 日志或 RDB 快照。其中，AOF 日志提供了三种日志写回策略：no、everysec、always。这三种写回策略依赖文件系统的两个系统调用完成，也就是 write 和 fsync。

write 只要把日志记录写到**内核缓冲区**，就可以返回了，并不需要等待日志实际写回到磁盘；而 fsync 需要把日志记录写回到磁盘后才能返回，时间较长。下面这张表展示了三种写回策略所执行的系统调用。

考虑**采用高速的固态硬盘作为 AOF 日志的写入设备**。

#### 操作系统：swap

内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，swap 触发后影响的是 Redis 主 IO 线程，这会极大地增加 Redis 的响应时间。

通常，触发 swap 的原因主要是**物理机器内存不足**，对于 Redis 而言，有两种常见的情况：

- Redis 实例自身使用了大量的内存，导致物理机器的可用内存不足；

- 和 Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 Redis 实例的内存量变少，进而触发 Redis 发生 swap。

  针对这个问题解决思路：**增加机器的内存或者使用 Redis 集群**。

#### 操作系统：内存大页

Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。

Redis 为了提供数据可靠性保证，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以，此时，Redis 主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。在这一过程中，Redis 就会采用写时复制机制，也就是说，一旦有数据要被修改，Redis 并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。

如果采用了内存大页，那么，即使客户端请求只修改 100B 的数据，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响 Redis 正常的访存操作，最终导致性能变慢。

### 小结

1. 获取 Redis 实例在当前环境下的基线性能。
2. 是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。
3. 是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。
4. 是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。
5. Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。
6. Redis 实例的内存使用是否过大？发生 swap 了吗？如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况。
7. 在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。
8. 是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。
9. 是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上。

## 十三、删除数据后，为什么内存占用率还是很高？

用 top 命令查看时，还会发现 Redis 占用了很多内存。

当数据删除后，Redis 释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以，操作系统仍然会记录着给 Redis 分配了大量内存。

Redis 释放的内存空间可能并不是连续的。

### 内存碎片是如何形成的？

- 内因：内存分配器的分配策略

Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc。

jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。这样的分配方式本身是为了减少分配次数，但会形成碎片的风险。

- 外因：键值对大小不一样和删改操作

### 如何判断是否有内存碎片？

Redis 自身提供了 INFO 命令 ```INFO memory```

内存碎片率 = 操作系统实际分配给 Redis 的物理内存空间 / Redis 为了保存数据实际申请使用的空间 >1.5需要处理

### 如何清理内存碎片？

重启 **Redis** 实例.

- 如果 Redis 中的数据没有持久化，那么，数据就会丢失；
- 即使 Redis 数据持久化了，我们还需要通过 AOF 或 RDB 进行恢复，恢复时长取决于 AOF 或 RDB 的大小，如果只有一个 Redis 实例，恢复阶段无法提供服务。

从 4.0-RC3 版本以后，Redis 自身提供了一种**内存碎片自动清理**的方法。

基本机制：当有数据把一块连续的内存空间分割成好几块不连续的空间时，操作系统就会把数据拷贝到别处。此时，数据拷贝需要能把这些数据原来占用的空间都空出来，把原本不连续的内存空间变成连续的空间。

**碎片清理是有代价的**。

Redis 是单线程，在数据拷贝时，Redis 只能等着。

数据拷贝还需要注意顺序，操作系统需要先拷贝 D，并释放 D 的空间后，才能拷贝 B。这种对顺序性的要求，会进一步增加 Redis 的等待时间。

> 具体什么时候清理，需同时满足这两个条件：
>
> - active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理；
>
> - active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。
>
> 控制清理操作占用的 CPU 时间比例的上、下限：
>
> - active-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；
> - active-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理。
>

## 十四、缓冲区

- 缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是 **Redis 客户端和服务器端**之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写 Redis，或者是主从节点全量同步失败，需要重新执行。
- 缓冲区溢出导致命令数据丢失：**主节点上的复制积压缓冲区属于环形缓冲区**，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。

1. 针对命令数据发送过快过大的问题，对于普通客户端来说可以避免 bigkey，而对于复制缓冲区来说，就是避免过大的 RDB 文件。

2. 针对命令数据处理较慢的问题，解决方案就是减少 Redis 主线程上的阻塞操作，例如使用异步的删除操作。

3. 针对缓冲区空间过小的问题，解决方案就是使用 client-output-buffer-limit 配置项设置合理的**输出缓冲区**、复制缓冲区和复制积压缓冲区大小。输入缓冲区的大小默认是固定的，无法修改。

## 十五、Redis缓存

- Redis 缓存具体是怎么工作的？
- Redis 缓存如果满了，该怎么办？
- 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
- Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis 缓存可以使用快速固态硬盘吗？

### 1. 缓存的特征

一个系统中的不同层之间的访问速度不一样，所以我们才需要缓存，这样就可以把一些需要频繁访问的数据放在缓存中，以加快它们的访问速度。

CPU、内存和磁盘这三层的访问速度从几十 ns 到 100ns，再到几 ms，性能的差异很大。

如果每次 CPU 处理数据时，都要从 ms 级别的慢速磁盘中读取数据，然后再进行处理，那么，CPU 只能等磁盘的数据传输完成。这样一来，**高速的 CPU 就被慢速的磁盘拖累**了，整个计算机系统的运行速度会变得非常慢。

所以，计算机系统中，默认有两种缓存：

- **CPU 里面的末级缓存**，即 LLC，用来缓存内存中的数据，避免每次从内存中存取数据；

- **内存中的高速页缓存**，即 page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。

**缓存的第一个特征**：在一个层次化的系统中，缓存一定是一个**快速子系统**，数据存在缓存中时，能避免每次从慢速子系统中存取数据。对应到互联网应用来说，Redis 就是快速子系统，而数据库就是慢速子系统了。

**缓存的第二个特征**：缓存系统的**容量**大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中。

所以，缓存和后端慢速系统之间，必然存在数据写回和再读取的交互过程。简单来说，缓存中的数据需要按一定规则淘汰出去，写回后端系统，而新的数据又要从后端系统中读取进来，写入缓存。

缓存的两个特征，分别是在分层系统中，数据暂存在快速子系统中有助于加速访问；缓存容量有限，缓存写满时，数据需要被淘汰。而 Redis 天然就具有高性能访问和数据淘汰机制，正好符合缓存的这两个特征的要求，所以非常适合用作缓存。

#### 缓存的类型

按照 Redis 缓存是否接受写请求，我们可以把它分成只读缓存和读写缓存。

##### 只读缓存

所有最新的数据都在数据库中。

##### 读写缓存

所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作。**最新的数据是在 Redis 中**。一旦出现掉电或宕机，内存中的数据就会丢失。

**同步直写策略优先保证数据可靠性，而异步写回策略优先提供快速响应。**

**同步直写**是指，写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回。保证了数据可靠性。

同步直写会降低缓存的访问性能。这是因为缓存中处理写请求的速度是很快的，而数据库处理写请求的速度较慢。即使缓存很快地处理了写请求，也需要等待数据库处理完所有的写请求，才能给应用返回结果，这就增加了缓存的响应延迟。

**异步写回**策略，则是优先考虑了响应延迟。此时，所有写请求都先在缓存中处理。**等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库。**这样一来，处理这些数据的操作是在缓存中进行的，很快就能完成。只不过，如果发生了掉电，而它们还没有被写回数据库，就会有丢失的风险了。

选择只读缓存，还是读写缓存，主要看我们对写请求是否有加速的需求。

- 如果需要对写请求进行加速，我们选择读写缓存；
- 如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存。

举个例子，在商品大促的场景中，商品的库存信息会一直被修改。如果每次修改都需到数据库中处理，就会拖慢整个应用，此时，我们通常会选择读写缓存的模式。而在短视频 App 的场景中，虽然视频的属性有很多，但是，一般确定后，修改并不频繁，此时，在数据库中进行修改对缓存影响不大，所以只读缓存模式是一个合适的选择。

### 2. 缓存满了怎么办？

**缓存数据的淘汰机制**。包括两步：第一，根据策略，筛选出不重要的数据；第二，将这些数据从缓存中删除。

#### 设置多大的缓存容量合适？

需要结合应用数据实际访问特征和成本开销来综合考虑的。

大容量缓存成本也会更高。一般把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销。

#### Redis 缓存有哪些淘汰策略？

![img](/Users/liuxiaohan1/Documents/秋招/pictures/04bdd13b760016ec3b30f4b02e133df6.webp)

noeviction 策略。缓存被写满，再有写请求来时，Redis 不再提供服务，直接返回错误。

可以用 EXPIRE 命令对一批键值对设置过期时间。

- volatile-ttl 在筛选时，会**针对设置了过期时间的键值对**，根据过期时间的先后进行删除，越早过期的越先被删除。
- volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。
- volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。
- volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。

- allkeys-random 策略，从所有键值对中随机选择并删除数据；
- allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。
- allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。

#### 过期键的删除策略

- **定时删除**：主动删除。在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间到来时，立即执行对键的删除操作。**缺点**：服务器很忙的时候，cpu时间还要用在删除和当前任务无关的过期键上，影响服务器的响应时间和吞吐量。此外创建定时器需要使用一个链表实现，查找一个事件的时间复杂度为ON，并不能高效处理大量事件。

- **惰性删除**：被动删除。放任键过期时间不管，但是每次获取键时，都检查取得的键是否过期，如果过期的话，就删除该键，没有过期，就返回该键。**缺点**：如果数据库中有非常多的过期键，而这些过期键又恰好没有被访问到，那么他们也许永远不会被删除（除非用户手动执行flushdb）

- **定期删除**：主动删除。每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。优点**：定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对cpu时间的影响。除此之外，通过定期删除过期键，定期删除策略有效地减少了因为过期键而带来的内存浪费。**

  难点是确定删除操作执行的时长和频率：如果删除操作执行的太频繁，或者执行的时间太长，定期删除策略就会退化成定时删除策略，以至于将cpu时间过多的消耗在删除过期键上面。
  如果删除操作执行的太少，或者执行的时间太短，定期删除策略又会和惰性删除策略一样，出现浪费内存的情况

#### Redis是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典来保存数据过期的时间。
检查键是否存在于过期字典，如果存在，检查当前unix时间戳是否大于键的过期时间。

### 3. 如何解决缓存和数据库的数据不一致问题？

#### 删改数据

![img](/Users/liuxiaohan1/Documents/秋招/pictures/2c376b536aff9d14d8606499f401cdac.png)

#### 如何解决数据不一致问题？

重试机制。具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。

如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。

##### 情况一：先删除缓存，再更新数据库。

假设线程 A 删除缓存值后，还没有来得及更新数据库（比如说有网络延迟），线程 B 就开始读取数据了，那么这个时候，线程 B 会发现缓存缺失，就只能去数据库读取。这会带来两个问题：

1. 线程 B 读取到了旧值；
2. 线程 B 是在缓存缺失的情况下读取的数据库，所以，它还会把旧值写入缓存，这可能会导致其他线程从缓存中读到旧值。

等到线程 B 从数据库读取完数据、更新了缓存后，线程 A 才开始更新数据库，此时，缓存中的数据是旧值，而数据库中的是最新值，两者就不一致了。

**在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间，再进行一次缓存删除操作。**

之所以要加上 sleep 的这段时间，就是为了让线程 B 能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程 A 再进行删除。所以，线程 A sleep 的时间，就需要大于线程 B 读取数据再写入缓存的时间。这个时间怎么确定呢？建议你在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。（**线程B读取到错误数据已经不可避免 避免的是其他线程读到错误的值**）

这样一来，其它线程读取数据时，会发现缓存缺失，所以会从数据库中读取最新值。**因为这个方案会在第一次删除缓存值后，延迟一段时间再次进行删除，所以我们也把它叫做“延迟双删”**。

##### 情况二：先更新数据库值，再删除缓存值。

如果线程 A 删除了数据库中的值，但还没来得及删除缓存值，线程 B 就开始读取数据了，那么此时，线程 B 查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程 A 一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。

- 删除缓存值或更新数据库**失败**而导致数据不一致，你可以使用**重试**机制确保删除或更新操作成功。

- 在删除缓存值、更新数据库的这两步操作中，有其他线程的**并发**读操作，导致其他线程读取到旧值，应对方案是**延迟双删**。

#### 小结

对于读写缓存，采用同步写回策略，可以保证缓存和数据库中的数据一致。

只读缓存的情况比较复杂。

![img](/Users/liuxiaohan1/Documents/秋招/pictures/11ae5e620c63de76448bc658fe6a496f.png)

建议优先使用**先更新数据库再删除缓存**的方法，原因主要有两个：

1. 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；
2. 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。

不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求**必须读取一致**的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端**暂存并发读请求**，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。

##### 直接更新缓存和删除缓存值相比

如果我们直接在缓存中更新缓存值，等到下次数据再被访问时，业务应用可以直接从缓存中读取数据，这是它的一大好处。

不足之处在于，当有数据更新操作时，我们要保证缓存和数据库中的数据是一致的，这就可以采用重试或延时双删方法。除了写+读并发，还有写+写并发，需要加分布式锁。更新操作也比删除操作慢。需要在业务应用中增加额外代码，有一定的开销。更新的值也不一定被访问到。

### 4. 如何解决缓存雪崩、击穿、穿透难题？

#### 缓存雪崩

缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，大量请求发送到数据库层，导致数据库层的压力激增。

- **第一个原因是：缓存中有大量数据同时过期，导致大量请求无法得到处理。**

针对大量数据同时失效带来的缓存雪崩问题，有两种解决方案。

1. **避免给大量的数据设置相同的过期时间**。用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数，既避免了大量数据同时过期，也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。

2. **服务降级**，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。
   - 对于非核心数据（例如电商商品属性）时，暂停从缓存中查询，直接返回预定义信息、空值或是错误信息；
   - 核心数据（例如电商商品库存），继续通过数据库读取。

- **第一个原因是：Redis 实例故障宕机，从而发生缓存雪崩。**

1. 在业务系统中，实现**服务熔断、请求限流**机制。
   - 发生缓存雪崩时，为了防止引发数据库雪崩，甚至是系统崩溃，**暂停业务应用对缓存系统的接口访问**。客户端直接返回，直到 Redis 缓存实例恢复服务。
   - 请求限流。在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。

2. **事前预防**。通过主从节点的方式构建 Redis 缓存高可靠集群，避免了由于缓存实例宕机而导致的缓存雪崩问题。

#### 缓存击穿

针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时。

对于访问特别频繁的热点数据，我们就不设置过期时间了。

- 缓存雪崩是发生在大量数据 **” 同时 “** 失效的场景下，

- 缓存击穿，是发生在某个热点数据失效的场景下。

#### 缓存穿透

缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中。

- 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；

- 恶意攻击：专门访问数据库中没有的数据。

**第一种方案是，缓存空值或缺省值。**

针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值。

**第二种方案是，使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。**

布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：

- 首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值。
- 然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。
- 最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作。

如果数据不存在（例如，数据库里没有写入数据），我们也就没有用布隆过滤器标记过数据，那么，bit 数组对应 bit 位的值仍然为 0。

当需要查询某个数据时，我们就执行刚刚说的计算过程，先得到这个数据在 bit 数组中对应的 N 个位置。紧接着，我们查看 bit 数组中这 N 个位置上的 bit 值。只要这 N 个 bit 值有一个不为 1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存。

**最后一种方案是，在请求入口的前端进行请求检测。**

请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉。

![img](/Users/liuxiaohan1/Documents/秋招/pictures/b5bd931239be18bef24b2ef36c70e9e1.png)

### 5. 缓存污染

#### LFU

当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把**访问次数**最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的**访问时效性**，把距离上一次访问时间更久的数据淘汰出缓存。

## 十六、Redis并发访问：无锁的原子操作

多个用户同时下单，就会对缓存中的商品库存并发更新，有了并发写操作。

加锁是一种常用的方法，在读取数据前，客户端需要先获得锁，否则就无法进行操作。当一个客户端获得锁后，就会一直持有这把锁，直到客户端完成数据更新，才释放这把锁。

**原子操作是另一种提供并发访问控制的方法**。原子操作是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。既能保证并发控制，还减少对系统并发性能的影响。

### Redis 的两种原子操作方法

1. 把多个操作在 Redis 中实现成一个操作，也就是单命令操作；
2. 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本。

Redis 是使用单线程来串行处理客户端的请求操作命令的，所以，当 Redis 执行某个命令操作时，其他命令是无法执行的。Redis 的快照生成、AOF 重写这些操作，可以使用后台线程或者是子进程执行，这些操作只是读取数据，不需要对它们做并发控制。

- Redis 提供了 INCR/DECR 命令，把读数据、数据增减、写回数据三个操作转变为一个原子操作。

- Redis 会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本中操作的原子性。

## 十七、如何使用Redis实现分布式锁？

Redis 属于分布式系统，当有多个客户端需要争抢锁时，我们必须要保证，**这把锁不能是某个客户端本地的锁**。否则的话，其它客户端是无法访问这把锁的，当然也就不能获取这把锁了。

所以，在分布式系统中，当有多个客户端需要获取锁时，我们需要分布式锁。此时，锁是保存在一个共享存储系统中的，可以被多个客户端共享访问和获取。

### 单机上的锁和分布式锁的联系与区别

锁本身可以用一个变量表示。

- 变量值为 0 时，表示没有线程获取锁；

- 变量值为 1 时，表示已经有线程获取到锁了。

分布式锁同样可以**用一个变量**来实现。客户端加锁和释放锁的操作逻辑，也和单机上的加锁和释放锁操作逻辑一致：**加锁时同样需要判断锁变量的值，根据锁变量值来判断能否加锁成功；释放锁时需要把锁变量值设置为 0，表明客户端不再持有锁。**

但是，和线程在单机上操作锁不同的是，在分布式场景下，锁变量需要由一个**共享存储系统来维护**，只有这样，多个客户端才可以通过访问共享存储系统来访问锁变量。相应的，**加锁和释放锁的操作就变成了读取、判断和设置共享存储系统中的锁变量值。**

实现分布式锁的两个要求。

- 要求一：分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性；

- 要求二：共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了。在实现分布式锁时，我们需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。

### 基于单个 Redis 节点实现分布式锁

基于单个 Redis 实例实现分布式锁时，对于加锁操作，我们需要满足三个条件。

1. 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；
2. 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；
3. 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值（可以随机生成字符串，看业务），用于标识客户端。

#### 加锁

在Redis 2.6.12之前，由于setnx 不支持设置过期时间，所以加锁的过期相对比较复杂，通常会为以下几步：

通过setnx获取锁，如果成功，再设置过期时间。 如果还没来得及执行expire操作，客户端就宕机了，将导致该锁永久有效，所以有下面这一步。
如果客户端setnx获取锁失败，则检查一下该锁是否设置了过期时间，如果未设置过期时间则设置。这一步是对上面问题的弥补，如果某个创建锁的客户端在未执行expire时就宕机了，其它客户端可以通过修改key的过期时间，来保证锁最终会被Redis清除，自己有获取锁的机会。不过同样有一个问题，就是客户端之间的时间有可能会被覆盖，但实际业务中，通常这种覆盖是可以被接受的。

2.6.12之后：

加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参：

1. 第一个为key，我们使用key来当锁，因为key是唯一的。
2. 第二个为value，我们传的是requestId，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId业务中用的是唯一用户pin。
3. 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作；
4. 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。
5. 第五个为time，与第四个参数相呼应，代表key的过期时间。

总的来说，执行上面的set()方法就只会导致两种结果：1. 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。2. 已有锁存在，不做任何操作。

加锁代码满足我们可靠性里描述的三个条件。

- 首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。
- 其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。
- 最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。

##### 错误：

- 使用jedis.setnx()和jedis.expire()组合实现加锁：
  - 两条Redis命令，不具有原子性，如果程序在执行完setnx()之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。网上之所以有人这样实现，是因为低版本的jedis并不支持多参数的set()方法。
- 使用jedis.setnx()命令实现加锁，其中key是锁，value是锁的过期时间。执行过程：1. 通过setnx()方法尝试加锁，如果当前锁不存在，返回加锁成功。2. 如果锁已经存在则获取锁的过期时间，和当前时间比较，如果锁已经过期，则设置新的过期时间，返回加锁成功。
  - 1. 由于是客户端自己生成过期时间，所以需要强制要求分布式下每个客户端的时间必须同步。 2. 当锁过期的时候，如果多个客户端同时执行jedis.getSet()方法，那么虽然最终只有一个客户端可以加锁，但是这个客户端的锁的过期时间可能被其他客户端覆盖。3. 锁不具备拥有者标识，即任何客户端都可以解锁。

#### 解锁

1. Lua脚本：首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。

2. 通过客户端事务的方式如下：获取锁的值，判断是不是自己创建的，如果是则删除。之所有要加事务，是因为在判断和del之间，锁有可能突然过期，然后其它线程突然获取到了锁，此时执行del操作就会把其它客户端创建的锁给释放掉。所以通常会用watch和事务来处理。如下

##### 错误：

- 直接使用jedis.del()方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。
- 分成两条命令去执行
  - 客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。

### 基于多个 Redis 节点实现高可靠的分布式锁

分布式锁算法 Redlock。

Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。

Redlock 算法的实现需要有 N 个独立的 Redis 实例。接下来，我们可以分成 3 步来完成加锁操作。

第一步是，**客户端获取当前时间**。

第二步是，**客户端按顺序依次向 N 个 Redis 实例执行加锁操作**。

这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。当然，如果某个 Redis 实例发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间。

如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。

第三步是，**一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时**。

客户端只有在满足下面的这两个条件时，才能认为是加锁成功。

- 条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；
- 条件二：客户端获取锁的总耗时没有超过锁的有效时间。

在满足了这两个条件后，我们需要**重新计算这把锁的有效时间**，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。

当然，如果客户端在和所有实例执行完加锁操作后，没能同时满足这两个条件，那么，客户端向所有 Redis 节点发起释放锁的操作。

在 Redlock 算法中，释放锁的操作和在单实例上释放锁的操作一样，只要**执行释放锁的 Lua 脚本**就可以了。这样一来，只要 N 个 Redis 实例中的半数以上实例能正常工作，就能保证分布式锁的正常工作了。

### 实现

Redis 锁主要利用 Redis 的 setnx 命令。

- 加锁命令：SETNX key value，当键不存在时，对键进行设置操作并返回成功，否则返回失败。KEY 是锁的唯一标识，一般按业务来决定命名。
- 解锁命令：DEL key，通过删除键值对释放锁，以便其他线程可以通过 SETNX 命令来获取锁。
- 锁超时：EXPIRE key timeout, 设置 key 的超时时间，以保证即使锁没有被显式释放，锁也可以在一定时间后自动释放，避免资源被永远锁住。

则加锁解锁伪代码如下：

```java
if (setnx(key, 1) == 1){
    expire(key, 30)
    try {
        //TODO 业务逻辑
    } finally {
        del(key)
    }
}
```

上述锁实现方式存在一些问题：

#### SETNX 和 EXPIRE 非原子性

如果 SETNX 成功，在设置锁超时时间后，服务器挂掉、重启或网络问题等，导致 EXPIRE 命令没有执行，锁没有设置超时时间变成死锁。

使用 lua 脚本封装成一个操作。

#### 锁误解除

如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。

通过在 value 中设置当前线程加锁的标识，在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。可生成一个 UUID 标识当前线程，使用 lua 脚本做验证标识和解锁操作。

#### 超时解锁导致并发

如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。

A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题：

- 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
- 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。

#### 不可重入

当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

在本地记录记录重入次数，如 Java 中使用 ThreadLocal 进行重入次数统计。

本地记录重入次数虽然高效，但如果考虑到过期时间和本地、Redis 一致性的问题，就会增加代码的复杂性。另一种方式是 Redis Map 数据结构来实现分布式锁，既存锁的标识也对重入次数进行计数。

#### 无法等待锁释放

上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。

- 可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
- 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。

#### 集群问题

##### 1. 主备切换

为了保证 Redis 的可用性，一般采用主从方式部署。主从数据同步有异步和同步两种方式，Redis 将指令记录在本地内存 buffer 中，然后异步将 buffer 中的指令同步到从节点，从节点一边执行同步的指令流来达到和主节点一致的状态，一边向主节点反馈同步情况。

在包含主从模式的集群部署方式中，当主节点挂掉时，从节点会取而代之，但客户端无明显感知。当客户端 A 成功加锁，指令还未同步，此时主节点挂掉，从节点提升为主节点，新的主节点没有锁的数据，当客户端 B 加锁时就会成功。

##### 2. 集群脑裂

集群脑裂指因为网络问题，导致 Redis master 节点跟 slave 节点和 sentinel 集群处于不同的网络分区，因为 sentinel 集群无法感知到 master 的存在，所以将 slave 节点提升为 master 节点，此时存在两个不同的 master 节点。Redis Cluster 集群部署方式同理。

当不同的客户端连接不同的 master 节点时，两个客户端可以同时拥有同一把锁。

## 十八、事务机制：Redis能实现ACID属性吗？

### Redis 如何实现事务？

Redis 通过 MULTI、EXEC、DISCARD 和 WATCH 四个命令来支持事务机制。

第一步，客户端要使用一个命令显式地表示一个事务的开启。在 Redis 中，这个命令就是 MULTI。

第二步，客户端把事务中本身要执行的具体操作（例如增删改数据）发送给服务器端。这些操作就是 Redis 本身提供的数据读写命令，例如 GET、SET 等。 Redis 实例只是把这些命令暂存到一个命令队列中，并不会立即执行。

第三步，客户端向服务器端发送提交事务的命令，让数据库实际执行第二步中发送的具体操作。Redis 提供的 EXEC 命令就是执行事务提交的。当服务器端收到 EXEC 命令后，才会实际执行命令队列中的所有命令。

![img](/Users/liuxiaohan1/Documents/秋招/pictures/9571308df0620214d7ccb2f2cc73a250.png)

**原子性**：

- 命令入队时就报错，会放弃事务执行，保证原子性；
- 命令入队时没报错，实际执行时报错，但还是会把正确的命令执行完，不保证原子性；
- EXEC 命令执行时实例故障，导致事务执行失败。如果开启了 AOF 日志，redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。

**一致性：**

- 命令入队时就报错，事务本身就会被放弃执行，可以保证数据库的一致性。

- 命令入队时没报错，实际执行时报错，有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性。

- EXEC 命令执行时实例发生故障，实例故障后会进行重启。如果我们没有开启 RDB 或 AOF，那么，实例故障重启后，数据都没有了，数据库是一致的。

  如果我们使用了 RDB 快照，因为 RDB 快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到 RDB 快照中，使用 RDB 快照进行恢复时，数据库里的数据也是一致的。

  如果我们使用了 AOF 日志，而事务操作还没有被记录到 AOF 日志时，实例就发生了故障，那么，使用 AOF 日志恢复的数据库数据是一致的。如果只有部分操作被记录到了 AOF 日志，我们可以使用 redis-check-aof 清除事务中已经完成的操作，数据库恢复后也是一致的。

**隔离性**：

1. 并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证；

   **WATCH 机制**的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。

2. 并发操作在 EXEC 命令后执行，此时，隔离性可以保证。

   因为 Redis 是用单线程执行命令，而且，EXEC 命令执行后，Redis 会保证先把命令队列中的所有命令执行完。所以，在这种情况下，并发操作不会破坏事务的隔离性

**Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。**不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、一致性和隔离性这三个属性。

Redis 中并没有提供回滚机制。虽然 Redis 提供了 DISCARD 命令，但是，这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。

原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。所以，我给你一个小建议：严格按照 Redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性。

### 脑裂

![img](https://static001.geekbang.org/resource/image/13/72/1339e1bfe6d07da8477342ba5fyy9872.jpg)

![img](https://static001.geekbang.org/resource/image/95/66/959240fa59c2bb9f5ddb7df4b318af66.jpg)

脑裂发生的原因主要是原主库发生了假故障，我们来总结下假故障的两个原因。

1. 和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如 CPU 资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常。
2. 主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap，短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。

问题是出在原主库发生假故障后仍然能接收请求上，Redis 已经提供了两个配置项来限制主库的请求处理：

- min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；
- min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。

我们可以分别给它们设置一定的阈值，假设为 N 和 T。这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求了。

即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。

等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。

举个例子。假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。

在实际应用中，可能会因为网络暂时拥塞导致从库暂时和主库的 ACK 消息超时。在这种情况下，并不是主库假故障，我们也不用禁止主库接收请求。

所以，我给你的建议是，假设从库有 K 个，可以将 min-slaves-to-write 设置为 K/2+1（如果 K 等于 1，就设为 1），将 min-slaves-max-lag 设置为十几秒（例如 10～20s），在这个配置下，如果有一半以上的从库和主库进行的 ACK 消息延迟超过十几秒，我们就禁止主库接收客户端写请求。

### Redis 6.0

Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。

- 阶段一：服务端和客户端建立 Socket 连接，并分配处理线程

  首先，主线程负责接收建立连接请求。当有客户端请求和实例建立 Socket 连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。紧接着，主线程通过轮询方法把 Socket 连接分配给 IO 线程。

- 阶段二：IO 线程读取并解析请求

  主线程一旦把 Socket 分配给 IO 线程，就会进入阻塞状态，等待 IO 线程完成客户端请求读取和解析。因为有多个 IO 线程在并行处理，所以，这个过程很快就可以完成。

- 阶段三：主线程执行请求操作

  等到 IO 线程解析完请求，主线程还是会以单线程的方式执行这些命令操作。

  ![img](https://static001.geekbang.org/resource/image/58/cd/5817b7e2085e7c00e63534a07c4182cd.jpg)

- 阶段四：IO 线程回写 Socket 和主线程清空全局队列

  当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待 IO 线程把这些结果回写到 Socket 中，并返回给客户端。

  和 IO 线程读取和解析请求一样，IO 线程回写 Socket 时，也是有多个线程在并发执行，所以回写 Socket 的速度也很快。等到 IO 线程回写 Socket 完毕，主线程会清空全局队列，等待客户端的后续请求。

![img](https://static001.geekbang.org/resource/image/2e/1b/2e1f3a5bafc43880e935aaa4796d131b.jpg)